{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> A1: Predicting Car Price</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, I will solve a problem, i.e., Chaky company makes some car but he has difficulty setting the price for the car. I will make a simple web-based car price prediction system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a regression problem trying to predict car price.\n",
    "\n",
    "<ul>The followings describe the feautres:\n",
    "<br></br>\n",
    "<b>\n",
    "<li>name\n",
    "<li>year\n",
    "<li>selling_price\n",
    "<li>km_driven\n",
    "<li>fuel\n",
    "<li>seller_type\n",
    "<li>transmission\n",
    "<li>owner\n",
    "<li>mileage\n",
    "<li>engine\n",
    "<li>max_power\n",
    "<li>torque\n",
    "<li>seats\n",
    "</b>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Task1. Preparing the datasets </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1. Importing Libraries </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "np.__version__, pd.__version__, sns.__version__, matplotlib.__version__, sns.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Load Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv\n",
    "df = pd.read_csv('/root/.vscode-server/data/lab1_Cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the first row of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistical info Hint:\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data types of the input data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Exploratory Data Analysis</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA is an essential step to inspect the data, so to better understand nature of the given data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Renaming </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename \"Name\" Column to \"brand\", I will not rename for the rest columns as it is already perfect.\n",
    "df.rename (\n",
    "    columns= {'name' : 'brand'}, inplace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the columns name\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Label Encoding </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I would like to change feature \"owner\" values to numerical values by mapping <b> First Owner = 1, ..., Test Drive Cars = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the owner column unique value\n",
    "df['owner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import labelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['owner'] = le.fit_transform (df['owner'])\n",
    "df['owner'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I will do label encoding for \"transmission\" feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for my array\n",
    "df['transmission'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transmission'] = le.fit_transform(df['transmission'])\n",
    "df['transmission'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Other Preparation </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature \"Fuel\" >> I will remove all rows with 'CNG' and 'LPG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows where 'fuel' == 'CNG'\n",
    "# Using drop() to delete rows based on column value\n",
    "df.drop(df[df['fuel'] == 'CNG'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check after dropping CNG\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows where 'fuel' == 'LPG'\n",
    "# Using drop() to delete rows based on column value\n",
    "df.drop(df[df['fuel'] == 'LPG'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check after dropping LPG\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature 'mileage', I will remove 'kmpl' using df.mileage.str.split and \n",
    "convert column to numerical type (e.g. float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usage of split\n",
    "# series.str.split (pad = None, *, n = -1, expand = flase, regex = None)\n",
    "\n",
    "#df with split value of columns (set expand = True: it will return a df after splitted the values; n=1: total separations will be 1 time)\n",
    "df1 = df[\"mileage\"].str.split (\" \",n = 1, expand = True)\n",
    "\n",
    "#making the splitted 0 column as 'mileage' features\n",
    "df['mileage'] = df1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the datatype of a series\n",
    "df['mileage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert 'mileage' feature DType to float\n",
    "df['mileage']=df['mileage'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mileage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature 'engine', I will remove 'CC' and convert it datatype to numerical (float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check feature 'engine'\n",
    "df['engine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove CC of engine and put the results into temporary dataframe\n",
    "df2 = df['engine'].str.split (' ', n = 1, expand = True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the value: update the resulted df[0] to the original df\n",
    "df['engine']  = df2[0]\n",
    "\n",
    "#check the df['engine']\n",
    "df['engine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dtype of 'engin' to float\n",
    "df['engine'] = df['engine'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature 'maxpower', I will repeat the same steps as what I did to feature 'engine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check 'maxpower'\n",
    "df['max_power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove bhp\n",
    "df3 = df['max_power'].str.split (\" \", n = 1, expand = True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace\n",
    "df['max_power'] = df3[0]\n",
    "df['max_power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change dtype of max_power\n",
    "df['max_power'] = df['max_power'].astype (\"float64\")\n",
    "df['max_power']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature 'brand', I will take only the first word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "df['brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "df4 = df['brand'].str.split (\" \", n = 1, expand = True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brand'] = df4[0]\n",
    "df['brand'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the feature \"torque\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop\n",
    "df = df.drop (columns = ['torque'])\n",
    "\n",
    "#check the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will remove some samples of which 'owner' == test driver car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "\n",
    "#check my df['owner'] sample to make sure it is correct or not\n",
    "df[df['owner'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the samples for test drive car\n",
    "df.drop(df[df['owner'] == 3].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the shape\n",
    "df.shape\n",
    "\n",
    "# df[df['owner'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 'sellingprice', I will transform using the log transform as it is a big number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check selling_price\n",
    "df['selling_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_transform for selling_price\n",
    "df['selling_price'] = np.log(df['selling_price'])\n",
    "df['selling_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the final dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.1 Univariate Analysis</h5>\n",
    "\n",
    "Single variable exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Couontplot</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot (data = df, x = 'selling_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot (data = df, x = 'fuel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot (data = df, x = 'seller_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot (data = df, x = 'transmission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot (data = df, x = 'owner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot (data = df, x = 'seats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Distribution Plot</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df, x = 'engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df, x = 'year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.2 Multivariate analysis</h5>\n",
    "\n",
    "Multiple variable exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Boxplot</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot (x = df['year'], y = df['brand']);\n",
    "plt.ylabel(\"Brand\")\n",
    "plt.xlabel(\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot (x = df['engine'], y = df['fuel']);\n",
    "plt.xlabel(\"Engine\")\n",
    "plt.ylabel(\"Fuel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot (x = df['seats'], y = df['selling_price']);\n",
    "plt.xlabel(\"seats\")\n",
    "plt.ylabel(\"selling price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot (x = df['fuel'], y = df['selling_price']);\n",
    "plt.xlabel(\"fuel\")\n",
    "plt.ylabel(\"selling price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot (x = df['seller_type'], y = df['selling_price']);\n",
    "plt.xlabel(\"seller_type\")\n",
    "plt.ylabel(\"selling_price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Scatterplot </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot (x = df ['year'], y = df['selling_price'], hue = df['fuel'])\n",
    "#diesel car are more expensive than petrol car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot (x = df ['year'], y = df['selling_price'], hue = df['seller_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot (x = df ['selling_price'], y = df['brand'], hue = df['seats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot (x = df ['year'], y = df['selling_price'], hue = df['seats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Correlation Matrix</h5>\n",
    "\n",
    "Correlation matrix is used to find strong factors predicting the life expectancy. It's also for checking features are too correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check out heatmap\n",
    "plt.figure (figsize = (15,8))\n",
    "my_df = df.select_dtypes (exclude = [object])\n",
    "sns.heatmap (my_df.corr(), annot = True, cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Predictive Power Score</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppscore as pps\n",
    "\n",
    "#before using pps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ppscore_df = df.select_dtypes (exclude = [object])\n",
    "matrix_df = pps.matrix(df)[['x','y','ppscore']].pivot (columns='x', index = 'y', values= 'ppscore')\n",
    "\n",
    "#plot\n",
    "plt.figure (figsize = (15,8))\n",
    "sns.heatmap (matrix_df, vmin = 0, vmax = 1, cmap = \"Blues\", linewidths = 0.5, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Feature Engineering</>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Feature Selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x is strong features\n",
    "X = df[['transmission','max_power']]\n",
    "\n",
    "#y is the selling_price label\n",
    "y = df['selling_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h5>Train Test Split</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split (X,y, test_size = 0.3, random_state = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Preprocessing</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Null Values</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null vaules in train set\n",
    "X_train[['transmission','max_power']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null values in test set\n",
    "X_test[['transmission','max_power']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot (data=df, x='transmission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df, x = 'max_power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After checking the null values for my features: 'transmission' and 'max_power', only 'max_power' feature has the null values.\n",
    "# for the max_power, I will fill with median value, because we already \n",
    "#syntax df.fillna (value = none, method=none, axis = none, inplace = false, limit = none, downcase = none)\n",
    "#X_train['max_power'].fillna ()\n",
    "\n",
    "X_train['max_power'].fillna(X_train['max_power'].median(),inplace = True)\n",
    "X_test['max_power'].fillna(X_train['max_power'].median(),inplace = True)\n",
    "\n",
    "#for our label that is selling_price, there is no null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noneed\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Checking Outliers</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary of columns\n",
    "col_dict = {'transmission':1, 'max_power':2}\n",
    "\n",
    "#detect outliers in each variable using box plots\n",
    "plt.figure(figsize=(20,30))\n",
    "           \n",
    "for variable,i in col_dict.items():\n",
    "    plt.subplot(5,4,i)\n",
    "    plt.boxplot(X_train[variable])\n",
    "    \n",
    "    plt.title(variable)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_count(col, data = X_train):\n",
    "    \n",
    "    #calculate 25% quatile and 75% quatile\n",
    "    q75, q25 = np.percentile (data[col],[75,25])\n",
    "    \n",
    "    #calculate your inter quatile\n",
    "    iqr = q75-q25\n",
    "    \n",
    "    #min_val and max_val\n",
    "    min_val = q25 - (iqr * 1.5)\n",
    "    max_val = q75 + (iqr * 1.5)\n",
    "    \n",
    "    #count number of outliers, which are the data that are less than min_val and more than max_val calculated above\n",
    "    outlier_count = len(np.where((data[col] > max_val) | (data[col] < min_val))[0])\n",
    "    \n",
    "    #calculate the percentage of the outliers\n",
    "    outlier_percent = round (outlier_count/len(data[col])*100,2)\n",
    "    \n",
    "    if(outlier_count > 0):\n",
    "        print(\"\\n\" + 15*\"-\" + col + 15*'-' + \"\\n\")\n",
    "        print ('Number of outliers: {}'.format (outlier_count))\n",
    "        print ('Percentage of data that is outlier : {}'.format(outlier_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    outlier_count(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Scaling </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#feature scaling helps improve reach convergence faster\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the shape of all X_train, y_train, y_test\n",
    "print (\"Shape of X_train: \", X_train.shape)\n",
    "print (\"Shape of X_test: \", X_test.shape)\n",
    "print (\"Shape of y_train: \", y_train.shape)\n",
    "print (\"Shape of y_test: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Modelling </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    IMPORTANT NOTES FOR USNIGN SKLEARN:<br>\n",
    "    define some algorithms and compare them using cross-validation: using scikit-learn which provide a huge pool of ML algorithms. <BR>\n",
    "    need to aware the data shape that sklearn wants <br>\n",
    "    sklearn requires two inputs: X and y: <br>\n",
    "    X is feature matrix, shape = [n_samples,n_features] and y is label vector,shape = [n_samples, ] or [n_samples, n_targets]<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit (X_train,y_train)\n",
    "yhat = lr.predict (X_test)\n",
    "\n",
    "print (\"MSE: \", mean_squared_error (y_test, yhat))\n",
    "print (\"r2: \", r2_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation + Grid serch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing regression algorithms libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#put the models that we will use into a list\n",
    "algorithms = [LinearRegression(), SVR(), KNeighborsRegressor(), DecisionTreeRegressor(random_state=0), RandomForestRegressor(n_estimators = 100, random_state = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do simple cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "#lists for keeping MSE\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "\n",
    "#defining number of splits using kfold\n",
    "kfold = KFold (n_splits = 8, shuffle = True)\n",
    "\n",
    "#finding the scores for all the algorithms\n",
    "for i, model in enumerate (algorithms):\n",
    "    scores  = cross_val_score (model, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    print(f\"{algorithms[i]} - Score: {scores}; Mean: {scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems random forest regressor do very well. So, I will do the grid search the find the best version of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Grid Search </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid =  {'bootstrap' : [True], 'max_depth' : [5,10, None], 'n_estimators': [5,6,7,8,9,10,11,12,13,14,15]}\n",
    "\n",
    "rf = RandomForestRegressor (random_state = 1)\n",
    "\n",
    "grid = GridSearchCV (estimator=rf,\n",
    "                     param_grid=param_grid,\n",
    "                     cv=kfold,\n",
    "                     n_jobs=-1,\n",
    "                     return_train_score=True,\n",
    "                     refit=True,\n",
    "                     scoring='neg_mean_squared_error')\n",
    "\n",
    "#fit your grid search\n",
    "grid.fit (X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best your gird_search's best score\n",
    "best_mse = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 7. Testing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = grid.predict (X_test)\n",
    "mean_squared_error(y_test,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Part 2 - 4. Feature Selection </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection\n",
    "X2 = df[['engine','year']]\n",
    "y2 = df['selling_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = 0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "\n",
    "#check for null values\n",
    "X_train2[['engine','year']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2[['engine','year']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df, x = 'engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot (data = df, x = 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill for the engine\n",
    "X_train2['engine'].fillna (X_train2['engine'].median(), inplace = True)\n",
    "X_test2['engine'].fillna (X_train2['engine'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2[['engine', 'year']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking outliers\n",
    "#create dictionary column\n",
    "col_dict2 = {'engine':1, 'year':2}\n",
    "\n",
    "plt.figure (figsize = (20,30))\n",
    "\n",
    "for variable,i in col_dict2.items():\n",
    "    plt.subplot (5,4,i)\n",
    "    plt.boxplot (X_train2[variable])\n",
    "    plt.title (variable)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_count (col, data = X_train2):\n",
    "    q752, q252 = np.percentile (data[col], [75, 25])\n",
    "    \n",
    "    iqr = q752-q252\n",
    "    \n",
    "    min_val2 = q252 - (iqr * 1.5)\n",
    "    max_val2 = q752 + (iqr * 1.5)\n",
    "    \n",
    "    outlier_count2 = len(np.where ((data[col]> max_val2) | (data[col]<min_val2))[0])\n",
    "    \n",
    "    outlier_percentate2 = round (outlier_count2 / len(data[col])*100,2)\n",
    "    \n",
    "    if (outlier_count2 > 0):\n",
    "        print (\"\\n\" +15*'-' + col + 15*'-' + \"\\n\")\n",
    "        print (\"Number of outliers: {}\".format (outlier_count2))\n",
    "        print ('Percentage of data that is outlier:{}'.format(outlier_percentate2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train2.columns:\n",
    "    outlier_count (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling\n",
    "scaler2 = StandardScaler()\n",
    "X_train2 = scaler2.fit_transform(X_train2)\n",
    "X_test2  = scaler2.fit_transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling\n",
    "#list\n",
    "train_mse2 = []\n",
    "test_mse2 = []\n",
    "\n",
    "for i, model in enumerate (algorithms):\n",
    "    scores2 = cross_val_score (model, X_train2, y_train2, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    print (f\"{algorithms[i]} - Scores: {scores2}; Mean: {scores2.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search\n",
    "grid.fit (X_train2, y_train2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mse = grid.best_score_\n",
    "best_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "yhat2 = grid.predict(X_test2)\n",
    "mean_squared_error (y_test2, yhat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 8. Analysis of Feature Importance </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Algorithm way</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stored in this variable\n",
    "#random forest grid\n",
    "\n",
    "rf = grid.best_estimator_\n",
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot\n",
    "plt.barh (X.columns, rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "plt.barh (X.columns[sorted_idx], rf.feature_importances_[sorted_idx])\n",
    "plt.xlabel (\"RandomForestRegressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Permutation way </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "per_imp = permutation_importance(rf, X_test2, y_test2)\n",
    "\n",
    "#plot\n",
    "sorted_idx = per_imp.importances_mean.argsort()\n",
    "plt.barh (X.columns[sorted_idx], per_imp.importances_mean[sorted_idx])\n",
    "plt.xlabel (\"RandomForestRegressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Shape Way </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer (rf)\n",
    "shap_values = explainer.shap_values (X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
